{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Topics in Urban Informatics || Greg Dobler || June 13, 2016\n",
    "-----------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structure of this class\n",
    "Basics of image processing and computer vision with useful tool building along the way <br>\n",
    "One homework problem which will consist of submitting code <br>\n",
    "Useful reading: <i>Programming Computer Vision with Python</i>, Jan Erik Solem\n",
    "\n",
    "<br>\n",
    "\n",
    "## Getting started with scientific python\n",
    "NumPy -- arrays (2D and 3D), vectorized operations, basic functionality <br>\n",
    "SciPy -- functions, transformations, analysis <br>\n",
    "Matplotlib -- plotting, viewing, visualizations (static and interactive)\n",
    "\n",
    "<br>\n",
    "\n",
    "## Image processing and Computer Vision\n",
    "What are images from a data perspective? <br>\n",
    "How are images loaded displayed and handled? <br>\n",
    "What are some basic image processing taks? <br>\n",
    "What can we learn from images? <br><br>\n",
    "<b>Video is not particularly <i>special</i>, it's just a series of images to be analyzed together</b>\n",
    "\n",
    "----------------------\n",
    "\n",
    "## 1D\n",
    "Let's look at a \"time series\".  First some imports that will be useful:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: MacOSX\n",
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "import scipy.ndimage as nd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# -- helps for interactive plotting with notebooks\n",
    "%pylab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we load in the one-dimensional data (which has been saved as a numpy array) and define a plotting function to view the data in a couple of different ways."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = np.load('output/ml_flat.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig0 = plt.figure(0)\n",
    "def showit(fac,sep=100.):\n",
    "    fig0.clf()\n",
    "    ax0 = fig0.add_subplot(1,1,1)\n",
    "    lin0 = ax0.plot(range(data.size/fac), \n",
    "                    data.reshape(data.size/fac,fac) + \n",
    "                    sep*np.arange(fac),lw=0.05,color='k')\n",
    "    fig0.canvas.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "showit(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "This one-dimensional \"time series\" can be sliced and plotted stacked on top of itself.  For example, cut it in half and plot the two curves:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "showit(2,200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we progressively cut further, stacking each time.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "showit(954,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig1, ax1 = plt.subplots(num=1)\n",
    "im1 = ax1.imshow(data.reshape(data.size/954,954).T[::-1,:])\n",
    "ax1.grid(0)\n",
    "fig1.canvas.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For *many* reasons, displaying 2D information in a rainbow color scheme is a poor choice.  Here are some good defaults to set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.rcParams[\"image.cmap\"] = \"gist_gray\"\n",
    "plt.rcParams[\"image.interpolation\"] = \"nearest\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 1D vs 2D arrays\n",
    "\n",
    "Grayscale images are 2D <b>arrays</b> but in many cases can be thought of (and treated as) 1D arrays.<br>\n",
    "<br>\n",
    "Many data analysis tasks you've already seen can be handled exactly the same:<br>\n",
    ". correlations<br>\n",
    ". means and variances<br>\n",
    ". multivariate regressions<br>\n",
    "<br>\n",
    "others will be different:<br>\n",
    ". filters<br>\n",
    ". derivatives<br>\n",
    ". rotations<br>\n",
    "<br>\n",
    "But since this is a numpy array things are easily <b><i>vectorized</i></b> and fast.  For example, let's look at derivatives.  First the 1D case:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xx = np.linspace(-20,20,1000)\n",
    "yy = np.cos(xx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig3, ax3 = plt.subplots(num=3)\n",
    "lin3a, = ax3.plot(xx,yy,'darkred')\n",
    "lin3b, = ax3.plot(xx[1:],(yy[1:]-yy[:-1])/(xx[1]-xx[0]),\n",
    "                  'dodgerblue')\n",
    "fig3.canvas.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which can be used to find edges,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xx = np.linspace(-20,20,1000)\n",
    "yy = 1.0*(xx>4.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lin3a.set_data(xx,yy)\n",
    "lin3b.set_data(xx[1:],(yy[1:]-yy[:-1])/(xx[1]-xx[0]))\n",
    "lin3b.set_visible(False)\n",
    "ax3.set_ylim(-5,5)\n",
    "fig3.canvas.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lin3b.set_visible(True)\n",
    "fig3.canvas.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same thing is true in 2D, but now we can do all rows at once,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img = data.reshape(data.size/954,954).T[::-1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig4, ax4 = plt.subplots(1,2,num=4)\n",
    "im4a = ax4[0].imshow(img)\n",
    "im4b = ax4[1].imshow(img[:,5:]-img[:,:-5])\n",
    "fig4.canvas.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... or we can do all columns at once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "im4b.set_data(img[5:,:]-img[:-5,:])\n",
    "fig4.canvas.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For completeness, let's do rows and columns (not simultaneously!) take the absolute value and add them together.  This is the simplest version of an edge detector,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "edges_simp = np.abs(img[5:,5:]-img[:-5,5:]) + \\\n",
    "    np.abs(img[5:,5:]-img[5:,:-5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "im4b.set_data(edges_simp)\n",
    "fig4.canvas.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which is often combined with thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "im4b.set_data(edges_simp>60)\n",
    "im4b.set_clim(0,1)\n",
    "fig4.canvas.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see it's not doing great, it's missing some edges and there's a lot of noise.  We'll fix this later...\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(always be aware of your imports and <b><u><i>preserve namespaces</i></u></b>!!!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: MacOSX\n",
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "import scipy.ndimage as nd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%pylab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Reading images into python\n",
    "\n",
    "There are many ways to read images into a usable data structure in python.  Lots of good modules exist, some of the most popular being:<br>\n",
    ". scipy.ndimage<br>\n",
    ". PIL (python imaging library)<br>\n",
    ". scikit-image<br>\n",
    ". opencv<br>\n",
    "<br>\n",
    "Each of these has its pros and cons, we'll almost exclusively be using scipy.ndimage since we can load the data directly into a numpy array and it lets us stay \"close\" to the data.<br>\n",
    "<br>\n",
    "This notebook is running in a directory with a subdirectory called \"images\" where the Mona Lisa image is stored.  To load it into a numpy array,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dpath = 'images'\n",
    "fname = 'ml.jpg'\n",
    "infile = os.path.join(dpath,fname)\n",
    "img_ml = nd.imread(infile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have the image ready to use as a numpy array (with all of its associated methods).  Some important things to note about this array though are its shape and type,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape : (954, 640, 3)\n",
      "type  : uint8\n"
     ]
    }
   ],
   "source": [
    "print(\"shape : {0}\\ntype  : {1}\".format(img_ml.shape,img_ml.dtype))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 3D arrays, data types, and heatmaps\n",
    "\n",
    "While grayscale images are 2D arrays, color images are 3D (... and sometimes 4D) data <i>cubes</i>.  Typically, these are stored as 8-bit unsigned integers meaning that the value a given pixel can take is between $0$ and $255 = 2^8 - 1$.<br>\n",
    "<br>\n",
    "Fortunately, when matplotlib sees a 3D data cube it knows what to do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ysize = 10.\n",
    "xsize = ysize*float(img_ml.shape[1])/float(img_ml.shape[0])\n",
    "\n",
    "fig5, ax5 = plt.subplots(num=5,figsize=[xsize,ysize])\n",
    "fig5.subplots_adjust(0,0,1,1)\n",
    "ax5.axis('off')\n",
    "im5 = ax5.imshow(img_ml)\n",
    "fig5.canvas.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CAUTION: matplotlib always \"interprets\" 3D data cubes as being unsigned 8-bit integers.  If your 3D data cube is <i>not</i> an unsigned 8-bit integer, the color matching will fail,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "im5.set_data(1.0*img_ml)\n",
    "fig5.canvas.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's say, for example, that you wanted to make the whole image fainter by a factor of $4$.  You can multiply by $0.25$ but be careful to change the type back to a uint8:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig6, ax6 = plt.subplots(1,3,num=6,figsize=[3*xsize,ysize])\n",
    "fig6.subplots_adjust(0,0,1,1,0,0)\n",
    "[i.axis('off') for i in ax6]\n",
    "im6a = ax6[0].imshow(img_ml)\n",
    "im6b = ax6[1].imshow(0.25*img_ml)\n",
    "im6c = ax6[2].imshow((0.25*img_ml).astype(np.uint8))\n",
    "fig6.canvas.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whenever processing an image, always use the highest precision you can and only go back to 8-bit integers for visualizations.<br>\n",
    "<br>\n",
    "Notice though what matplotlib does when the input array is <i>not</i> a 3D data cube:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img_ml_L\n",
      "  shape : (954, 640)\n",
      "  type  : float64\n"
     ]
    }
   ],
   "source": [
    "img_ml_L = img_ml.mean(2) # convert to gray scale by taking the mean across the color axis\n",
    "print(\"img_ml_L\\n  shape : {0}\\n  type  : {1}\".format(img_ml_L.shape,img_ml_L.dtype))\n",
    "\n",
    "fig7, ax7 = plt.subplots(num=7,figsize=[xsize,ysize])\n",
    "fig7.subplots_adjust(0,0,1,1)\n",
    "ax7.axis('off')\n",
    "im7 = ax7.imshow(img_ml_L)\n",
    "fig7.canvas.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the data is a 2D 64-bit float.  In this case matplotlib creates a heatmap and intensity is preserved regardless of amplitude.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cropping, negative, and overplotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Find a jpg from the internet and download it\n",
    "2. Load it into python using scipy.ndimage\n",
    "3. Display the full image\n",
    "4. Display only the upper left corner\n",
    "5. Display only the lower right corner\n",
    "6. Display only the central half of the image\n",
    "7. Diplay a negative of the full image\n",
    "8. Reset the right half of the image as the negative of itself\n",
    "9. Plot a step function with a transition at ncol/2 and height nrow\n",
    "10. Overshow the result of step 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Advanced (and relational) indexing: Part 1\n",
    "\n",
    "Numpy array indexing is fast and allows you to manipulate images with only a few lines of code.  As an example, we'll create the \"spotlight\" widget.\n",
    "\n",
    "First, it is often useful to create row and column index \"maps\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dpath = 'images'\n",
    "fname = 'ml.jpg'\n",
    "infile = os.path.join(dpath,fname)\n",
    "img_ml = nd.imread(infile)\n",
    "\n",
    "nrow, ncol = img_ml.shape[:2]\n",
    "rind = np.arange(nrow*ncol).reshape(nrow,ncol) // ncol\n",
    "cind = np.arange(nrow*ncol).reshape(nrow,ncol) % ncol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig8, ax8 = plt.subplots(1,2)\n",
    "ax8[0].imshow(rind)\n",
    "ax8[0].grid(0)\n",
    "ax8[1].imshow(cind)\n",
    "ax8[1].grid(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which will let us index on positions in the image through \"relational\" indexing.  For example, we can create a mask for our image,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mask = np.dstack([(rind<500).astype(np.uint8) for i \n",
    "                  in range(3)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(954, 640, 3)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ysize = 10.\n",
    "xsize = ysize*float(img_ml.shape[1]) / \\\n",
    "    float(img_ml.shape[0])\n",
    "\n",
    "fig9, ax9 = plt.subplots(num=9,\n",
    "                         figsize=[xsize,ysize])\n",
    "fig9.subplots_adjust(0,0,1,1)\n",
    "ax9.axis('off')\n",
    "im9 = ax9.imshow(img_ml*mask)\n",
    "fig9.canvas.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, let's make a circular aperature around a point in the image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rm, cm = 244, 302\n",
    "dist = np.sqrt((rind-rm)**2+(cind-cm)**2)\n",
    "\n",
    "im9.set_data(dist)\n",
    "im9.set_clim(0,500)\n",
    "fig9.canvas.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(954, 640)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mask = np.zeros(img_ml.shape,dtype=np.uint8)\n",
    "mask[dist<=100] = [1,1,1]\n",
    "\n",
    "im9.set_data(255*mask)\n",
    "fig9.canvas.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "im9.set_data(img_ml*mask)\n",
    "fig9.canvas.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### using Matplotlib's ginput() function\n",
    "\n",
    "The ginput() function let's you click on a point and grab its location from the matplotlib window.  For example,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xpos = 301.589552239\n",
      "ypos = 244.858208955\n"
     ]
    }
   ],
   "source": [
    "xpos, ypos = fig9.ginput()[0]\n",
    "\n",
    "print(\"xpos = {0}\\nypos = {1}\".format(xpos,ypos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(349.35074626865668, 181.57462686567169), (290.8432835820895, 324.85820895522386), (290.8432835820895, 324.85820895522386)]\n"
     ]
    }
   ],
   "source": [
    "print fig9.ginput(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rpos = 197\n",
      "cpos = 287\n"
     ]
    }
   ],
   "source": [
    "cpos, rpos = [int(round(i)) for i in \n",
    "              fig9.ginput()[0]]\n",
    "\n",
    "print(\"rpos = {0}\\ncpos = {1}\".format(rpos,cpos))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Advanced (and relational) indexing: Part 2\n",
    "\n",
    "In addition to indexing based on position within an image, we can index on pixel <i>values</i> which is useful for selecting subcomponents of an image that are not conected compoenents.  As an example, let's create an image consisting of a blue circle and line:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rind = np.arange(20000).reshape(200,100) // 100\n",
    "cind = np.arange(20000).reshape(200,100) % 100\n",
    "two_ln = ((rind>130) & (rind<150)) | \\\n",
    "    (np.sqrt((rind-50)**2+(cind-50)**2)<20)\n",
    "two_ln_c = np.dstack([64*two_ln, 128*two_ln, 192*two_ln]\n",
    "                     ).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig0, ax0 = plt.subplots(num=0,figsize=[5,10])\n",
    "fig0.subplots_adjust(0,0,1,1)\n",
    "ax0.grid('off')\n",
    "im0 = ax0.imshow(two_ln_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now identify the pixels in 2D which have the specified color and set those pixels to brown,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "index = (two_ln_c[:,:,0]==64) & \\\n",
    "    (two_ln_c[:,:,1]==128) & \\\n",
    "    (two_ln_c[:,:,2]==192)\n",
    "two_ln_c[index] = [192,128,64]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and replot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "im0.set_data(two_ln_c)\n",
    "fig0.canvas.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.close(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Example: Invasive Species"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Freshkills is a 2,200 acre former landfill on Staten Island that is in the process of being converted into a park (Freshkills park).  There is significant contamination by an invasive species called phragmites.\n",
    "\n",
    "#### CUSP PhD student Nick Johnson flew a balloon over Freshkills Park to image the extent of the phragmites invasion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dpath = 'images'\n",
    "dfile = 'phrag-annotated.png'\n",
    "infile = os.path.join(dpath,dfile)\n",
    "\n",
    "img = nd.imread(infile)[:,:,:3] # ignore the alpha channel\n",
    "\n",
    "nrow, ncol = img.shape[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xsize = 7.\n",
    "ysize = xsize*float(nrow)/float(ncol)\n",
    "\n",
    "fig0, ax0 = plt.subplots(num=0,figsize=[xsize,ysize])\n",
    "fig0.subplots_adjust(0,0,1,1); ax0.axis('off')\n",
    "im0 = ax0.imshow(img)\n",
    "fig0.canvas.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What separates the phragmites from the healthy vegetation is the <i>color</i>.  But we already know how to index on color, so let's get an idea of what color we're looking for.  If we zoom in on a region dominated by phragmites:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prow = [1460,1605]\n",
    "pcol = [4015,4354]\n",
    "\n",
    "ax0.add_patch(plt.Rectangle((pcol[0],prow[0]),\n",
    "                           pcol[1]-pcol[0],prow[1]-prow[0],\n",
    "              facecolor='none',edgecolor='orange',lw=2))\n",
    "ax0.set_xlim(pcol[0]-100,pcol[1]+100)\n",
    "ax0.set_ylim(prow[0]-100,prow[1]+100)\n",
    "fig0.canvas.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that it's a bit bluer than a region with healthy vegetation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hrow = [2650,2905]\n",
    "hcol = [570,915]\n",
    "\n",
    "ax0.add_patch(plt.Rectangle((hcol[0],hrow[0]),\n",
    "                           hcol[1]-hcol[0],hrow[1]-hrow[0],\n",
    "              facecolor='none',edgecolor='orange',lw=2))\n",
    "ax0.set_xlim(hcol[0]-100,hcol[1]+100)\n",
    "ax0.set_ylim(hrow[0]-100,hrow[1]+100)\n",
    "fig0.canvas.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ax0.set_xlim(0,ncol); ax0.set_ylim(nrow,0); fig0.canvas.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start understanding what kind of indexing we need to do, let's make some histograms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stamp_ph = img[prow[0]:prow[1],pcol[0]:pcol[1]]\n",
    "stamp_he = img[hrow[0]:hrow[1],hcol[0]:hcol[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig1, ax1 = plt.subplots(2,2,num=1,figsize=[2*xsize,xsize])\n",
    "clrs = ['firebrick','olivedrab','royalblue']\n",
    "\n",
    "[ax1[0,0].hist(stamp_ph[:,:,i].flatten(),bins=128,range=[0,255], \n",
    "               normed=True,facecolor=clrs[i]) for i in range(3)]\n",
    "[ax1[1,0].hist(stamp_he[:,:,i].flatten(),bins=128,range=[0,255], \n",
    "               normed=True,facecolor=clrs[i]) for i in range(3)]\n",
    "[i.set_yticklabels('') for j in ax1 for i in j]\n",
    "\n",
    "ax1[0,0].set_ylabel('phragmites')\n",
    "ax1[1,0].set_ylabel('healthy')\n",
    "fig1.canvas.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the first thing we can do is cut on the ratio of green to blue since the healthy vegetation has a ratio >1.5 for (more or less) all pixels in our patch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/local/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/IPython/kernel/__main__.py:1: RuntimeWarning: divide by zero encountered in divide\n",
      "  if __name__ == '__main__':\n",
      "/opt/local/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/IPython/kernel/__main__.py:1: RuntimeWarning: invalid value encountered in divide\n",
      "  if __name__ == '__main__':\n",
      "/opt/local/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/IPython/kernel/__main__.py:1: RuntimeWarning: invalid value encountered in less\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "hind = (1.0*img[:,:,1])/(1.0*img[:,:,2]) < 1.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hind = (1.0*img[:,:,1])/(1.0*img[:,:,2] + (img[:,:,2]==0)) < 1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.close(2)\n",
    "fig2, ax2 = plt.subplots(num=2,figsize=[xsize,ysize])\n",
    "fig2.subplots_adjust(0,0,1,1); ax2.axis('off')\n",
    "im2 = ax2.imshow(hind)\n",
    "fig2.canvas.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like we're getting phragmites, dirt, and road.  Let's look at the histograms of the dirt and road:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "drow = [2450,2880]\n",
    "dcol = [1905,2235]\n",
    "rrow = [1665,1790]\n",
    "rcol = [3600,3725]\n",
    "\n",
    "stamp_di = img[drow[0]:drow[1],dcol[0]:dcol[1]]\n",
    "stamp_rd = img[rrow[0]:rrow[1],rcol[0]:rcol[1]]\n",
    "\n",
    "for reg in [[drow,dcol],[rrow,rcol]]:\n",
    "    ax0.add_patch(plt.Rectangle((reg[1][0],reg[0][0]),\n",
    "                               reg[1][1]-reg[1][0],reg[0][1]-reg[0][0],\n",
    "                  facecolor='none',edgecolor='orange',lw=2))\n",
    "fig0.canvas.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "[ax1[0,1].hist(stamp_di[:,:,i].flatten(),bins=128,range=[0,255], \n",
    "               normed=True,facecolor=clrs[i]) for i in range(3)]\n",
    "[ax1[1,1].hist(stamp_rd[:,:,i].flatten(),bins=128,range=[0,255], \n",
    "               normed=True,facecolor=clrs[i]) for i in range(3)]\n",
    "\n",
    "ax1[0,1].set_ylabel('dirt')\n",
    "ax1[1,1].set_ylabel('road')\n",
    "\n",
    "fig1.canvas.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like \"dirt\" has a high red-to-blue ratio compared to phragmites, so we update our definition of phragmites colors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hind = ((1.0*img[:,:,1])/(1.0*img[:,:,2] + (img[:,:,2]==0)) < 1.5) & \\\n",
    "    ((1.0*img[:,:,0])/(1.0*img[:,:,2] + (img[:,:,2]==0)) < 1.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "im2.set_data(hind)\n",
    "fig2.canvas.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, the road mostly has values $>200$ while the phragmites are $<200$ (also let's use the fact that phragmites have red values which are $<150$ and the lines are black)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hind = ((1.0*img[:,:,1])/(1.0*img[:,:,2] + (img[:,:,2]==0)) < 1.5) & \\\n",
    "    ((1.0*img[:,:,0])/(1.0*img[:,:,2] + (img[:,:,2]==0)) < 1.2) & \\\n",
    "    (img.max(2)<200) & \\\n",
    "    (img[:,:,0]<150) & \\\n",
    "    (img.max(2)>50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "im2.set_data(hind)\n",
    "fig2.canvas.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Multiple frames (videos)\n",
    "\n",
    "Unlike single still images, multiple images of the same scene over time let you measure **time dependent** features (e.g., motion, color changes, etc.).  We will deal with already extracted frames from a video here, but an example about how that extraction can be done in python with OpenCV is <a href=\"http://tobilehman.com/blog/2013/01/20/extract-array-of-frames-from-mp4-using-python-opencv-bindings/\">here</a>. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DOT camera analysis\n",
    "\n",
    "The Department of Transportation has hundreds of traffic cameras located around the city.  Using this script:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    import os\n",
    "    import time\n",
    "\n",
    "    nframe   = 100\n",
    "    cmd_wget = \"wget http://207.251.86.238/cctv391.jpg\"\n",
    "    cmd_mv   = \"mv cctv391.jpg images/dot/cctv391_{0:03}.jpg\"\n",
    "\n",
    "    for ii in range(nframe):\n",
    "        os.system(cmd_wget)\n",
    "        os.system(cmd_mv.format(ii))\n",
    "        time.sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I grabbed 100 frames from camera overlooking the Manhattan bridge (and Lower East Side):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images/dot/cctv391_000.jpg\n",
      "images/dot/cctv391_001.jpg\n",
      "images/dot/cctv391_002.jpg\n",
      "images/dot/cctv391_003.jpg\n",
      "images/dot/cctv391_004.jpg\n",
      "images/dot/cctv391_005.jpg\n",
      "images/dot/cctv391_006.jpg\n",
      "images/dot/cctv391_007.jpg\n",
      "images/dot/cctv391_008.jpg\n",
      "images/dot/cctv391_009.jpg\n",
      "images/dot/cctv391_010.jpg\n",
      "images/dot/cctv391_011.jpg\n",
      "images/dot/cctv391_012.jpg\n",
      "images/dot/cctv391_013.jpg\n",
      "images/dot/cctv391_014.jpg\n",
      "images/dot/cctv391_015.jpg\n",
      "images/dot/cctv391_016.jpg\n",
      "images/dot/cctv391_017.jpg\n",
      "images/dot/cctv391_018.jpg\n",
      "images/dot/cctv391_019.jpg\n",
      "images/dot/cctv391_020.jpg\n",
      "images/dot/cctv391_021.jpg\n",
      "images/dot/cctv391_022.jpg\n",
      "images/dot/cctv391_023.jpg\n",
      "images/dot/cctv391_024.jpg\n",
      "images/dot/cctv391_025.jpg\n",
      "images/dot/cctv391_026.jpg\n",
      "images/dot/cctv391_027.jpg\n",
      "images/dot/cctv391_028.jpg\n",
      "images/dot/cctv391_029.jpg\n",
      "images/dot/cctv391_030.jpg\n",
      "images/dot/cctv391_031.jpg\n",
      "images/dot/cctv391_032.jpg\n",
      "images/dot/cctv391_033.jpg\n",
      "images/dot/cctv391_034.jpg\n",
      "images/dot/cctv391_035.jpg\n",
      "images/dot/cctv391_036.jpg\n",
      "images/dot/cctv391_037.jpg\n",
      "images/dot/cctv391_038.jpg\n",
      "images/dot/cctv391_039.jpg\n",
      "images/dot/cctv391_040.jpg\n",
      "images/dot/cctv391_041.jpg\n",
      "images/dot/cctv391_042.jpg\n",
      "images/dot/cctv391_043.jpg\n",
      "images/dot/cctv391_044.jpg\n",
      "images/dot/cctv391_045.jpg\n",
      "images/dot/cctv391_046.jpg\n",
      "images/dot/cctv391_047.jpg\n",
      "images/dot/cctv391_048.jpg\n",
      "images/dot/cctv391_049.jpg\n",
      "images/dot/cctv391_050.jpg\n",
      "images/dot/cctv391_051.jpg\n",
      "images/dot/cctv391_052.jpg\n",
      "images/dot/cctv391_053.jpg\n",
      "images/dot/cctv391_054.jpg\n",
      "images/dot/cctv391_055.jpg\n",
      "images/dot/cctv391_056.jpg\n",
      "images/dot/cctv391_057.jpg\n",
      "images/dot/cctv391_058.jpg\n",
      "images/dot/cctv391_059.jpg\n",
      "images/dot/cctv391_060.jpg\n",
      "images/dot/cctv391_061.jpg\n",
      "images/dot/cctv391_062.jpg\n",
      "images/dot/cctv391_063.jpg\n",
      "images/dot/cctv391_064.jpg\n",
      "images/dot/cctv391_065.jpg\n",
      "images/dot/cctv391_066.jpg\n",
      "images/dot/cctv391_067.jpg\n",
      "images/dot/cctv391_068.jpg\n",
      "images/dot/cctv391_069.jpg\n",
      "images/dot/cctv391_070.jpg\n",
      "images/dot/cctv391_071.jpg\n",
      "images/dot/cctv391_072.jpg\n",
      "images/dot/cctv391_073.jpg\n",
      "images/dot/cctv391_074.jpg\n",
      "images/dot/cctv391_075.jpg\n",
      "images/dot/cctv391_076.jpg\n",
      "images/dot/cctv391_077.jpg\n",
      "images/dot/cctv391_078.jpg\n",
      "images/dot/cctv391_079.jpg\n",
      "images/dot/cctv391_080.jpg\n",
      "images/dot/cctv391_081.jpg\n",
      "images/dot/cctv391_082.jpg\n",
      "images/dot/cctv391_083.jpg\n",
      "images/dot/cctv391_084.jpg\n",
      "images/dot/cctv391_085.jpg\n",
      "images/dot/cctv391_086.jpg\n",
      "images/dot/cctv391_087.jpg\n",
      "images/dot/cctv391_088.jpg\n",
      "images/dot/cctv391_089.jpg\n",
      "images/dot/cctv391_090.jpg\n",
      "images/dot/cctv391_091.jpg\n",
      "images/dot/cctv391_092.jpg\n",
      "images/dot/cctv391_093.jpg\n",
      "images/dot/cctv391_094.jpg\n",
      "images/dot/cctv391_095.jpg\n",
      "images/dot/cctv391_096.jpg\n",
      "images/dot/cctv391_097.jpg\n",
      "images/dot/cctv391_098.jpg\n",
      "images/dot/cctv391_099.jpg\n"
     ]
    }
   ],
   "source": [
    "path1 = 'images'\n",
    "path2 = 'dot'\n",
    "dpath = os.path.join(path1,path2)\n",
    "flist = [os.path.join(dpath,i) for i in \n",
    "         sorted(os.listdir(os.path.join(dpath)))]\n",
    "\n",
    "for i in flist:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "imgs = np.array([nd.imread(i) for i in flist])\n",
    "nimg, nrow, ncol = imgs.shape[0:3]\n",
    "xs = 6.5\n",
    "ys = 2*xs*float(nrow)/float(ncol)\n",
    "\n",
    "plt.close(0)\n",
    "fig0, ax0 = plt.subplots(2,1,num=0,figsize=[xs,ys])\n",
    "fig0.subplots_adjust(0,0,1,1,0,0)\n",
    "[i.axis('off') for i in ax0]\n",
    "im0a = ax0[0].imshow(imgs[0])\n",
    "fig0.canvas.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for img in imgs:\n",
    "    im0a.set_data(img)\n",
    "    fig0.canvas.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'd like to **roughly** count the number of cars on this section of the highway.  Let's first look at frame differences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "im0b = ax0[1].imshow(imgs[1].mean(-1) - imgs[0].mean(-1))\n",
    "fig0.canvas.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for ii in range(1,nimg):\n",
    "    im0a.set_data(imgs[ii])\n",
    "    im0b.set_data(imgs[ii].mean(-1) - imgs[ii-1].mean(-1))\n",
    "    fig0.canvas.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or taking the absolute value (note: if we were to count off of this we'd be roughly double counting...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "im0b.set_clim(0,128)\n",
    "\n",
    "for ii in range(1,nimg):\n",
    "    im0a.set_data(imgs[ii])\n",
    "    im0b.set_data(np.abs(imgs[ii].mean(-1) - imgs[ii-1].mean(-1)))\n",
    "    fig0.canvas.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do some thresholding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dimg = np.zeros([nrow,ncol])\n",
    "im0b.set_clim(0,1)\n",
    "\n",
    "for ii in range(1,nimg):\n",
    "    dimg[:,:] = np.abs(imgs[ii].mean(-1) - imgs[ii-1].mean(-1))\n",
    "    im0a.set_data(imgs[ii])\n",
    "    im0b.set_data(dimg>40)\n",
    "    fig0.canvas.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Background subtraction\n",
    "\n",
    "But again, we're double counting and adding noise.  Another method is to subtract the \"mean image\" from each frame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mimg = imgs.mean(0)\n",
    "\n",
    "im0a.set_data(mimg.clip(0,255).astype(np.uint8))\n",
    "fig0.canvas.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for ii in range(1,nimg):\n",
    "    im0a.set_data(imgs[ii])\n",
    "    im0b.set_data(np.abs(1.0*imgs[ii] - mimg).clip(0,255).astype(np.uint8))\n",
    "    fig0.canvas.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take the max of this difference in color space:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "im0b.set_clim([0,255])\n",
    "\n",
    "for ii in range(1,nimg):\n",
    "    im0a.set_data(imgs[ii])\n",
    "    im0b.set_data(np.abs(1.0*imgs[ii] - mimg).max(-1))\n",
    "    fig0.canvas.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we can do some clipping, but let's take a look at the distribution of brightnesses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.close(1)\n",
    "\n",
    "fig1,ax1 = plt.subplots(num=1)\n",
    "ax1.hist(np.log10(np.abs(1.0*imgs - mimg).max(-1).flatten()+1.0), bins=255,\n",
    "        facecolor=\"darkred\",lw=0)\n",
    "ax1.set_xlabel(\"brightness\")\n",
    "ax1.set_ylabel(\"PDF\")\n",
    "ax1.grid(1)\n",
    "fig1.canvas.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The logarithm of the difference values for the objects is something like $>1.5 \\approx 31$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "thr = 30\n",
    "im0b.set_clim([0,1])\n",
    "\n",
    "for ii in range(1,nimg):\n",
    "    im0a.set_data(imgs[ii])\n",
    "    im0b.set_data(np.abs(1.0*imgs[ii] - mimg).max(-1)>thr)\n",
    "    fig0.canvas.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bdilation = nd.morphology.binary_dilation\n",
    "berosion = nd.morphology.binary_erosion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "thr = 30\n",
    "im0b.set_clim([0,1])\n",
    "fgr = np.zeros([nrow,ncol],dtype=int)\n",
    "\n",
    "for ii in range(1,nimg):\n",
    "    fgr[:,:] = bdilation(berosion(np.abs(1.0*imgs[ii] - mimg).max(-1)>thr),iterations=2)\n",
    "    im0a.set_data(imgs[ii])\n",
    "    im0b.set_data(fgr)\n",
    "    fig0.canvas.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use our trick of a row map to generate a mask,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "col_mask = (np.arange(nrow*ncol).reshape(nrow,ncol)%ncol)<250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "thr = 30\n",
    "im0b.set_clim([0,1])\n",
    "fgr = np.zeros([nrow,ncol],dtype=int)\n",
    "\n",
    "for ii in range(1,nimg):\n",
    "    fgr[:,:] = bdilation(berosion(np.abs(1.0*imgs[ii] - mimg).max(-1)>thr),iterations=2)\n",
    "    im0a.set_data(imgs[ii])\n",
    "    im0b.set_data(fgr*col_mask)\n",
    "    fig0.canvas.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, we count the number of detected objects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "count = ax0[1].text(0,0,\"# of cars: \",va='top',\n",
    "                    fontsize=20,color='white')\n",
    "fig0.canvas.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "meas_label = nd.measurements.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "thr = 30\n",
    "sz_thr = 20 # only count objects greater than a size threshold\n",
    "im0b.set_clim([0,1])\n",
    "fgr = np.zeros([nrow,ncol],dtype=int)\n",
    "\n",
    "for ii in range(1,nimg):\n",
    "    fgr[:,:] = bdilation(berosion(np.abs(1.0*imgs[ii] - mimg).max(-1)>thr),iterations=2)\n",
    "    labs = meas_label(fgr*col_mask)\n",
    "    ncar = sum([1*((labs[0]==lab).sum()>sz_thr) for lab in range(1,labs[1]+1)])\n",
    "\n",
    "    im0a.set_data(imgs[ii])\n",
    "    im0b.set_data(fgr*col_mask)\n",
    "    count.set_text(\"# of cars: {0}\".format(ncar))\n",
    "    fig0.canvas.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Closing thoughts and recap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are some of the key concepts we've worked through.  They are broadly applicable, even well beyond the field of image processing and computer vision:\n",
    "\n",
    "- best practices for filesystem handling and namespaces\n",
    "- vectorized coding (indexing arrays to eliminate for loops)\n",
    "- object oriented plotting with matplotlib (for interactive plots)\n",
    "- thresholding for data subselection and masking\n",
    "- derivatives and edge detection through array shifts\n",
    "- combining 2D data with time series information"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
